# ------------------------------------------------------------------------------
# Copyright (c) Microsoft
# Licensed under the MIT License.
# Written by Ke Sun (sunk@mail.ustc.edu.cn)
# ------------------------------------------------------------------------------

import logging
import os
import time

import numpy as np
import numpy.ma as ma
from tqdm import tqdm
from PIL import Image

import torch
import torch.nn as nn
from torch.nn import functional as F

from utils.utils import AverageMeter
from utils.utils import get_confusion_matrix
from utils.utils import adjust_learning_rate
from utils.utils import Map16, Vedio
import utils.losses as loss_funcs
import utils.metrics as metrics

import utils.distributed as dist

vedioCap = Vedio('./output/cdOffice.mp4')
map16 = Map16(vedioCap)

def reduce_tensor(inp):
    """
    Reduce the loss from all processes so that 
    process with rank 0 has the averaged results.
    """
    world_size = dist.get_world_size()
    if world_size < 2:
        return inp
    with torch.no_grad():
        reduced_inp = inp
        torch.distributed.reduce(reduced_inp, dst=0)
    return reduced_inp / world_size


def train(config, epoch, num_epoch, epoch_iters, base_lr,
          num_iters, trainloader, optimizer, model, writer_dict):
    # Training
    model.train()

    batch_time = AverageMeter()
    ave_loss = AverageMeter()
    ave_acc  = AverageMeter()
    tic = time.time()
    cur_iters = epoch*epoch_iters
    # writer = writer_dict['writer']
    # global_steps = writer_dict['train_global_steps']

    for i_iter, batch in enumerate(trainloader, 0):
        images, labels, _, _ = batch
        images = images.cuda()
        labels = labels.long().cuda()

        losses, _, acc = model(images, labels)
        loss = losses.mean()
        acc  = acc.mean()

        if dist.is_distributed():
            reduced_loss = reduce_tensor(loss)
        else:
            reduced_loss = loss

        model.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - tic)
        tic = time.time()

        # update average loss
        ave_loss.update(reduced_loss.item())
        ave_acc.update(acc.item())

        lr = adjust_learning_rate(optimizer,
                                  base_lr,
                                  num_iters,
                                  i_iter+cur_iters)

        if i_iter % config.PRINT_FREQ == 0 and dist.get_rank() == 0:
            msg = 'Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, ' \
                  'lr: {}, Loss: {:.6f}, Acc:{:.6f}' .format(
                      epoch, num_epoch, i_iter, epoch_iters,
                      batch_time.average(), [x['lr'] for x in optimizer.param_groups], ave_loss.average(),
                      ave_acc.average())
            logging.info(msg)

    # writer.add_scalar('train_loss', ave_loss.average(), global_steps)
    # writer_dict['train_global_steps'] = global_steps + 1

def validate(config, testloader, model, writer_dict, loss_function):
    model.eval()
    ave_loss = AverageMeter()
    nums = config['model']['num_outputs']
    confusion_matrix = np.zeros(
        (config['model']['num_classes'], config['model']['num_classes'], nums))
    metricsFactory = metrics.Metrics_factory()
    mean_test_f1 = 0
    mean_test_acc = 0
    mean_test_bIoU = 0
    bIoU_array = []
    ct = 0
    with torch.no_grad():
        for idx, batch in enumerate(tqdm(testloader)):
            image, label, _, _ = batch
            size = label.size()
            image = image.cuda()
            label = label.long().cuda()
            label[label >= 1] -= 1

            pred = model(image)
            losses = loss_funcs.compute_loss(loss_function, pred[0], label)
            isw_loss = pred[1]
            pred = [torch.softmax(pred[0][0], dim = 1)]
            acc, f1, b_IoU, b_IoU_arr = metricsFactory.compute_metrics(pred[0], label.clone())

            # losses, pred, _ = model(image, label)
            if not isinstance(pred, (list, tuple)):
                pred = [pred]
            for i, x in enumerate(pred):
                x = F.interpolate(
                    input=x, size=size[-2:],
                    mode='bilinear', align_corners=config['model']['align_corners']
                )

                confusion_matrix[..., i] += get_confusion_matrix(
                    label,
                    x,
                    size,
                    config['model']['num_classes'],
                    config['train']['ignore_label']
                )

            loss = 0
            loss_coeffs = [0.7, 0.3]
            for j in range(len(losses)):
                loss = loss + loss_coeffs[j]*losses[j]
            loss = loss + 0.6*isw_loss
            acc = acc.mean()
            f1 = f1.mean()
            b_IoU = np.mean(b_IoU)
            # loss = losses.mean() + pred[1].item()
            if dist.is_distributed():
                reduced_loss = reduce_tensor(loss)
            else:
                reduced_loss = loss
            ave_loss.update(reduced_loss.item())
            mean_test_acc+=acc.item()
            mean_test_f1+=f1.item()
            mean_test_bIoU+=b_IoU
            bIoU_array.append(b_IoU_arr)

    if dist.is_distributed():
        confusion_matrix = torch.from_numpy(confusion_matrix).cuda()
        reduced_confusion_matrix = reduce_tensor(confusion_matrix)
        confusion_matrix = reduced_confusion_matrix.cpu().numpy()

    for i in range(1):
        pos = confusion_matrix[..., i].sum(1)
        res = confusion_matrix[..., i].sum(0)
        tp = np.diag(confusion_matrix[..., i])
        IoU_array = (tp / np.maximum(1.0, pos + res - tp))
        mean_IoU = IoU_array[1:].mean()
        if dist.get_rank() <= 0:
            logging.info('{} {} {}'.format(i, IoU_array, mean_IoU))

    bIoU_array = np.array(bIoU_array)
    mean_bIoU_array = [(np.sum(bIoU_array[:,0]) + list(bIoU_array[:,0]).count(-1))/(len(bIoU_array[:,0]) - list(bIoU_array[:,0]).count(-1)),
                       (np.sum(bIoU_array[:,1]) + list(bIoU_array[:,1]).count(-1))/(len(bIoU_array[:,1]) - list(bIoU_array[:,1]).count(-1))]

    return ave_loss.average(), mean_IoU, IoU_array, mean_bIoU_array, mean_test_acc/len(testloader), mean_test_f1/len(testloader), mean_test_bIoU/len(testloader)


def testval(config, test_dataset, testloader, model,
            sv_dir='', sv_pred=False):
    model.eval()
    confusion_matrix = np.zeros(
        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))
    with torch.no_grad():
        for index, batch in enumerate(tqdm(testloader)):
            image, label, _, name, *border_padding = batch
            size = label.size()
            pred = test_dataset.multi_scale_inference(
                config,
                model,
                image,
                scales=config.TEST.SCALE_LIST,
                flip=config.TEST.FLIP_TEST)

            if len(border_padding) > 0:
                border_padding = border_padding[0]
                pred = pred[:, :, 0:pred.size(2) - border_padding[0], 0:pred.size(3) - border_padding[1]]

            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:
                pred = F.interpolate(
                    pred, size[-2:],
                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS
                )
            
            # # crf used for post-processing
            # postprocessor = DenseCRF(   )
            # # image
            # mean=[0.485, 0.456, 0.406],
            # std=[0.229, 0.224, 0.225]
            # timage = image.squeeze(0)
            # timage = timage.numpy().copy().transpose((1,2,0))
            # timage *= std
            # timage += mean
            # timage *= 255.0
            # timage = timage.astype(np.uint8)
            # # pred
            # tprob = torch.softmax(pred, dim=1)[0].cpu().numpy()
            # pred = postprocessor(np.array(timage, dtype=np.uint8), tprob)    
            # pred = torch.from_numpy(pred).unsqueeze(0)
            
            confusion_matrix += get_confusion_matrix(
                label,
                pred,
                size,
                config.DATASET.NUM_CLASSES,
                config.TRAIN.IGNORE_LABEL)

            if sv_pred:
                sv_path = os.path.join(sv_dir, 'test_results')
                if not os.path.exists(sv_path):
                    os.mkdir(sv_path)
                test_dataset.save_pred2(image, pred, sv_path, name)

            if index % 100 == 0:
                logging.info('processing: %d images' % index)
                pos = confusion_matrix.sum(1)
                res = confusion_matrix.sum(0)
                tp = np.diag(confusion_matrix)
                IoU_array = (tp / np.maximum(1.0, pos + res - tp))
                mean_IoU = IoU_array.mean()
                logging.info('mIoU: %.4f' % (mean_IoU))

    pos = confusion_matrix.sum(1)
    res = confusion_matrix.sum(0)
    tp = np.diag(confusion_matrix)
    pixel_acc = tp.sum()/pos.sum()
    mean_acc = (tp/np.maximum(1.0, pos)).mean()
    IoU_array = (tp / np.maximum(1.0, pos + res - tp))
    mean_IoU = IoU_array.mean()

    return mean_IoU, IoU_array, pixel_acc, mean_acc


def test(config, test_dataset, testloader, model,
         sv_dir='', sv_pred=True):
    model.eval()
    with torch.no_grad():
        for _, batch in enumerate(tqdm(testloader)):
            image, size, name = batch
            size = size[0]
            pred = test_dataset.multi_scale_inference(
                config,
                model,
                image,
                scales=config.TEST.SCALE_LIST,
                flip=config.TEST.FLIP_TEST)

            if pred.size()[-2] != size[0] or pred.size()[-1] != size[1]:
                pred = F.interpolate(
                    pred, size[-2:],
                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS
                )

            if sv_pred:
                # mean=[0.485, 0.456, 0.406],
                #  std=[0.229, 0.224, 0.225]
                image = image.squeeze(0)
                image = image.numpy().transpose((1,2,0))
                image *= [0.229, 0.224, 0.225]
                image += [0.485, 0.456, 0.406]
                image *= 255.0
                image = image.astype(np.uint8)

                _, pred = torch.max(pred, dim=1)
                pred = pred.squeeze(0).cpu().numpy()
                map16.visualize_result(image, pred, sv_dir, name[0]+'.jpg')
                # sv_path = os.path.join(sv_dir, 'test_results')
                # if not os.path.exists(sv_path):
                #     os.mkdir(sv_path)
                # test_dataset.save_pred(image, pred, sv_path, name)
        vedioCap.releaseCap()
